{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Summary:\n",
    "#\n",
    "\n",
    "#\n",
    "# This Python script segments long audio files into smaller clips based on timing and transcription data stored in Azure Blob Storage.\n",
    "# Here's what it does:\n",
    "# \n",
    "# 1. Loads configuration settings (such as Azure container locations and working directories).\n",
    "# 2. Downloads audio files and corresponding transcript JSON files from Azure.\n",
    "# 3. Parses the transcript files to extract speech segments with timestamps and text.\n",
    "# 4. Splits the audio files into individual .wav clips for each segment using ffmpeg.\n",
    "# 5. Uploads the segmented audio files back to Azure, along with metadata like text and duration.\n",
    "# 6. Cleans up temporary local files used during processing.\n",
    "#\n",
    "# The result is a set of labeled audio clips, each matched to its corresponding spoken phrase.\n",
    "#\n",
    "\n",
    "# \n",
    "# This Notebook requires the following environment variables (.env file):\n",
    "# \n",
    "\n",
    "# SEGMENT_LOCAL_WORKING_DIR=\n",
    "# SEGMENT_AUDIO_INPUT_CONTAINER_SAS_URI=\n",
    "# SEGMENT_TEXT_INPUT_CONTAINER_SAS_URI=\n",
    "# SEGMENT_TEXT_INPUT_PATH=\n",
    "# SEGMENT_OUTPUT_CONTAINER_SAS_URI=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed6545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import uuid\n",
    "from azure.storage.blob import BlobBlock, ContainerClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "BASE_DELAY = 1\n",
    "\n",
    "def download_blobs(client: ContainerClient, dest: str, prefix: str=None):\n",
    "    blobs = list(client.list_blobs(\n",
    "        name_starts_with=prefix if prefix else None\n",
    "    ))\n",
    "\n",
    "    for blob in blobs:\n",
    "\n",
    "        local_blob_path = os.path.join(\n",
    "            dest, \n",
    "            os.path.basename(blob.name)\n",
    "        )\n",
    "\n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try: \n",
    "                with open(local_blob_path, \"wb\") as file:\n",
    "                    stream = client.download_blob(blob.name)\n",
    "                    for chunk in stream.chunks():\n",
    "                        file.write(chunk)\n",
    "                        \n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt == MAX_RETRIES:\n",
    "                    raise\n",
    "                else:\n",
    "                    print(f\"download_blobs() error: {str(e)}\")\n",
    "                    delay = BASE_DELAY * (2 ** (attempt -1))\n",
    "                    time.sleep(delay)                    \n",
    "\n",
    "def get_configuration() -> dict[str, str]:\n",
    "    return {\n",
    "        \"local_working_dir\": os.path.normpath(os.getenv('SEGMENT_LOCAL_WORKING_DIR')),\n",
    "        \"audio_input_container_sas\": os.getenv('SEGMENT_AUDIO_INPUT_CONTAINER_SAS_URI'),\n",
    "        \"text_input_container_sas\": os.getenv('SEGMENT_TEXT_INPUT_CONTAINER_SAS_URI'),\n",
    "        \"text_input_path\": os.getenv('SEGMENT_TEXT_INPUT_PATH'),\n",
    "        \"output_container_sas\": os.getenv('SEGMENT_OUTPUT_CONTAINER_SAS_URI')\n",
    "    }\n",
    "\n",
    "def get_container_client_from_sas(sas_uri: str) -> ContainerClient:\n",
    "    return ContainerClient.from_container_url(sas_uri)\n",
    "\n",
    "def get_temp_dir(path: str) -> str:\n",
    "    dir = os.path.join(path, str(uuid.uuid4()))\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    return dir\n",
    "\n",
    "def parse_translation_file(input: str) -> dict[str, str]:\n",
    "    with open(input, 'r') as content:\n",
    "        data = json.load(content)\n",
    "    \n",
    "    segments = []\n",
    "    if \"recognizedPhrases\" in data:\n",
    "        for phrase in data[\"recognizedPhrases\"]:\n",
    "            start_time = float(phrase[\"offsetInTicks\"]) / 10000000\n",
    "            duration = float(phrase[\"durationInTicks\"]) / 10000000\n",
    "            end_time = start_time + duration\n",
    "                \n",
    "            text = \"\"\n",
    "            if \"nBest\" in phrase and len(phrase[\"nBest\"]) > 0:\n",
    "                text = phrase[\"nBest\"][0].get(\"display\", \"\")\n",
    "                \n",
    "            segments.append({\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "                \"text\": text\n",
    "            })\n",
    "\n",
    "    return segments\n",
    "\n",
    "def remove_temp_dir(path: str):\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "def segment_audio(audio_source: str, text_source: str, dest: str) -> list[dict[str, str]]:\n",
    "    results = []\n",
    "    for text_file_name in os.listdir(text_source): # [FILENAME].wav.json\n",
    "        base_text_file_name = os.path.splitext(text_file_name)[0] # [FILENAME].wav\n",
    "        segments = parse_translation_file(os.path.join(text_source, text_file_name))\n",
    "        if segments:\n",
    "            for i, segment in enumerate(segments):\n",
    "                start_time = segment[\"start_time\"]\n",
    "                end_time = segment[\"end_time\"]\n",
    "                duration = end_time - start_time\n",
    "\n",
    "                segment_file_name = f\"{os.path.splitext(base_text_file_name)[0]}_seg{i:03d}.wav\"\n",
    "                segment_file_path = os.path.join(dest, segment_file_name)\n",
    "\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(os.path.join(audio_source, base_text_file_name), ss=start_time, t=duration)\n",
    "                    .output(segment_file_path, acodec='pcm_s16le', ar='16000', ac=1, format='wav')\n",
    "                    .run(quiet=True, overwrite_output=True)\n",
    "                )\n",
    "\n",
    "                results.append({\n",
    "                    \"name\": segment_file_name,\n",
    "                    \"path\": segment_file_path,\n",
    "                    \"start_time\": segment[\"start_time\"],\n",
    "                    \"end_time\": segment[\"end_time\"],\n",
    "                    \"duration\": duration,\n",
    "                    \"text\": segment[\"text\"]\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "def upload_blob_list_with_metadata(client: ContainerClient, blobs: list[dict[str, str]]):    \n",
    "    for blob in blobs:\n",
    "        if not os.path.isfile(blob[\"path\"]):\n",
    "            continue\n",
    "\n",
    "        blob_client = client.get_blob_client(blob[\"name\"])\n",
    "        \n",
    "        for attempt in range(1, MAX_RETRIES + 1):\n",
    "            try:\n",
    "                block_list = []\n",
    "                chunk_size = 4 * 1024 * 1024\n",
    "\n",
    "                with open(blob[\"path\"], \"rb\") as file:\n",
    "                    while True:\n",
    "                        chunk = file.read(chunk_size)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        block_id = str(len(block_list)).zfill(6)\n",
    "                        blob_client.stage_block(block_id=block_id, data=chunk)\n",
    "                        block_list.append(BlobBlock(block_id=block_id))\n",
    "                \n",
    "                blob_client.commit_block_list(block_list)\n",
    "                meta = {\n",
    "                    \"name\": str(blob[\"name\"]),\n",
    "                    \"duration\": str(blob[\"duration\"]),\n",
    "                    \"text\": str(blob[\"text\"])\n",
    "                }\n",
    "                blob_client.set_blob_metadata(meta)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt == MAX_RETRIES:\n",
    "                    raise\n",
    "                else:\n",
    "                    print(f\"upload_blob_list_with_metadata() error: {str(e)}\")\n",
    "                    delay = BASE_DELAY * (2 ** (attempt - 1))\n",
    "                    time.sleep(delay)\n",
    "\n",
    "def main():\n",
    "    print(\"Notebook Cell Running...\")\n",
    "\n",
    "    print(\"Loading configuration...\")\n",
    "    load_dotenv()\n",
    "    configuration = get_configuration()\n",
    "\n",
    "    print(\"Creating local input and output directories...\")\n",
    "    audio_input_dir = get_temp_dir(configuration[\"local_working_dir\"])\n",
    "    text_input_dir = get_temp_dir(configuration[\"local_working_dir\"])\n",
    "    output_dir = get_temp_dir(configuration[\"local_working_dir\"])\n",
    "\n",
    "    print(\"Obtaining input and output container clients...\")\n",
    "    audio_input_client = get_container_client_from_sas(configuration['audio_input_container_sas'])\n",
    "    text_input_client = get_container_client_from_sas(configuration['text_input_container_sas'])    \n",
    "    output_client = get_container_client_from_sas(configuration['output_container_sas'])\n",
    "\n",
    "    print(\"Downloading input files locally...\")\n",
    "    download_blobs(audio_input_client, audio_input_dir)\n",
    "    download_blobs(text_input_client, text_input_dir, configuration['text_input_path'])\n",
    "\n",
    "    print(\"Segmenting audio...\")\n",
    "    segments = segment_audio(audio_input_dir, text_input_dir, output_dir)\n",
    "\n",
    "    print(\"Uploading output files to cloud...\")\n",
    "    upload_blob_list_with_metadata(output_client, segments)\n",
    "\n",
    "    print(\"Cleaning local input and output directories...\")\n",
    "    remove_temp_dir(audio_input_dir)\n",
    "    remove_temp_dir(text_input_dir)\n",
    "    remove_temp_dir(output_dir)\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
